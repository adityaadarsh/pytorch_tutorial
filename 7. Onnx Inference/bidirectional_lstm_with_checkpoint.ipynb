{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transformations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Bidirectional Lstm Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BLSTM(nn.Module):\n",
    "    def __init__(self, imp_emb_dim, hidden_units, n_layers, output_classes):\n",
    "        super(BLSTM, self).__init__()\n",
    "\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_units = hidden_units\n",
    "\n",
    "        self.bilstm = nn.LSTM(input_size=imp_emb_dim,\n",
    "                               hidden_size=hidden_units,\n",
    "                               num_layers=n_layers,\n",
    "                               batch_first=True,\n",
    "                               bidirectional=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_units*imp_emb_dim*2, output_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Initialize the hidden state and cell state first for bidrectional lstm\n",
    "        h0 = torch.zeros(self.n_layers*2, x.size(0), self.hidden_units).to(device)\n",
    "        c0 = torch.zeros(self.n_layers*2, x.size(0), self.hidden_units).to(device)\n",
    "        \n",
    "        # Forward Propagation\n",
    "        out, _ = self.bilstm(x, (h0, c0))\n",
    "        out_flatten = torch.flatten(out, 1,-1)\n",
    "        x = self.fc(out_flatten)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "# check the network graph\n",
    "model = BLSTM(28, 5, 10, 10)\n",
    "\n",
    "# create a random variable and pass it to the model to check the network graph\n",
    "device = 'cpu'\n",
    "x = torch.randn(64, 28, 28)\n",
    "h0 = torch.zeros(10*2, x.size(0), 5).to(device)\n",
    "c0 = torch.zeros(10*2, x.size(0), 5).to(device)\n",
    "\n",
    "\n",
    "print(x.shape)\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersatnding RNN layer\n",
    "n_layer = 10\n",
    "hidden_size = 5\n",
    "emb_dim = 28\n",
    "batch_size = 64\n",
    "max_seq_length = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_cell = nn.LSTM(input_size=emb_dim,\n",
    "                               hidden_size=hidden_size,\n",
    "                               num_layers=n_layer,\n",
    "                               batch_first=True,\n",
    "                               bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 12, 28])\n",
      "torch.Size([20, 64, 5])\n",
      "torch.Size([20, 64, 5])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create a random variable and pass it to the model to check the network graph\n",
    "x = torch.randn(batch_size, max_seq_length, emb_dim)\n",
    "print(x.shape)\n",
    "\n",
    "hidden_state = torch.zeros(n_layer*2, batch_size, hidden_size)\n",
    "cell_state = torch.zeros(n_layer*2, batch_size, hidden_size)\n",
    "print(hidden_state.shape)\n",
    "print(cell_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_cell_output = lstm_cell(x, (hidden_state, cell_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_first=True\n",
    "len(lstm_cell_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 12, 10])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_cell_output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 64, 5]), torch.Size([20, 64, 5]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hidden gate output , cell gate output\n",
    "lstm_cell_output[1][0].shape, lstm_cell_output[1][1].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = 10\n",
    "n_layer = 10\n",
    "hidden_size = 5\n",
    "emb_dim = 28\n",
    "batch_size = 64\n",
    "max_seq_length = 12\n",
    "learning_rate = 0.001\n",
    "num_epochs = 9\n",
    "load_model = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and load the data from pytorch sample datasets\n",
    "# https://pytorch.org/vision/0.8/datasets.html\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"../dataset/\", train=True, transform=transformations.ToTensor(), download=True\n",
    ")\n",
    "train_datloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Understand the dataloader\n",
    "plt.title(\"sample image\")\n",
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_datloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset shape: torch.Size([60000, 28, 28])\n",
      "['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n"
     ]
    }
   ],
   "source": [
    "# train data shape and class labels\n",
    "print(\"train_dataset shape:\", train_dataset.data.shape)\n",
    "print(train_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_dataset shape: torch.Size([10000, 28, 28])\n",
      "['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n"
     ]
    }
   ],
   "source": [
    "test_dataset = datasets.MNIST(\n",
    "    root=\"../dataset/\", train=False, transform=transformations.ToTensor(), download=True\n",
    ")\n",
    "test_datloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(\"test_dataset shape:\", test_dataset.data.shape)\n",
    "print(test_dataset.classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLSTM(\n",
      "  (bilstm): LSTM(28, 5, num_layers=10, batch_first=True, bidirectional=True)\n",
      "  (fc): Linear(in_features=280, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = BLSTM(emb_dim, hidden_size, n_layer, n_class)\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise Loss And Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(checkpoint, filename='../checkpoint.pth.tar'):\n",
    "    print('==> saving checkpoint')\n",
    "    torch.save(checkpoint, filename)\n",
    "\n",
    "def load_checkpoint(checkpoint):\n",
    "    print('==> loading checkpoint')\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps to train the model\n",
    "1. For each epoch, iterate through the batch\n",
    "2. For each batch\n",
    "    * feed forward the input and target data of train to the model\n",
    "    * Calculate the loss and score\n",
    "    * Backpropogate the loss\n",
    "    * optimise the loss using optimiser() (gradient descent is one such optimiser) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def train(model):\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_idx, (data, target) in enumerate((train_datloader)):\n",
    "\n",
    "\n",
    "\n",
    "            # get data to cuda if possible\n",
    "            data = data.to(device)\n",
    "            # Squeeze the dim of data from (B X 1 X 28 X 28) to (B X 28 X 28)\n",
    "            data = data.squeeze(dim=1)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # feed forward the data to model\n",
    "            scores = model(data)\n",
    "            loss = criterion(scores, target)\n",
    "            # print(f\"epoch: {epoch}, batch: {batch_idx}, loss: {loss}\")\n",
    "            \n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad() # This will flush the gradients from the last iteration\n",
    "            loss.backward()\n",
    "\n",
    "            # optimise the loss (gradient descent or Adam step)\n",
    "            optimizer.step()\n",
    "\n",
    "        # Create a model checkpoint\n",
    "        if epoch % 3 == 0:\n",
    "            checkpoint = {'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict()}\n",
    "            save_checkpoint(checkpoint)\n",
    "            print(f\"epoch: {epoch}, batch: {batch_idx}, loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> saving checkpoint\n",
      "epoch: 0, batch: 937, loss: 0.5602800250053406\n",
      "==> saving checkpoint\n",
      "epoch: 3, batch: 937, loss: 0.059763237833976746\n",
      "==> saving checkpoint\n",
      "epoch: 6, batch: 937, loss: 0.12418629229068756\n"
     ]
    }
   ],
   "source": [
    "# get model to cuda if possible\n",
    "model = model.to(device)\n",
    "\n",
    "# Train the model\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> loading checkpoint\n"
     ]
    }
   ],
   "source": [
    "if load_model:\n",
    "    load_checkpoint(torch.load('../checkpoint.pth.tar'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check accuracy on train and test data (Validate model accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy on training & test to see how good our model\n",
    "def check_accuracy(loader, model):\n",
    "    \"\"\"\n",
    "    Check accuracy of our trained model given a loader and a model\n",
    "\n",
    "    Parameters:\n",
    "        loader: torch.utils.data.DataLoader\n",
    "            A loader for the dataset you want to check accuracy on\n",
    "        model: nn.Module\n",
    "            The model you want to check accuracy on\n",
    "\n",
    "    Returns:\n",
    "        acc: float\n",
    "            The accuracy of the model on the dataset given by the loader\n",
    "    \"\"\"\n",
    "\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    # We don't need to keep track of gradients here so we wrap it in torch.no_grad()\n",
    "    with torch.no_grad():\n",
    "        # Loop through the data\n",
    "        for x, y in loader:\n",
    "            # Move data to device\n",
    "            x = x.to(device=device)\n",
    "            # Squeeze the dim of x from (B X 1 X 28 X 28) to (B X 28 X 28)\n",
    "            x = x.squeeze(dim=1)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            # Forward pass\n",
    "            scores = model(x)\n",
    "            predictions = scores.argmax(1)\n",
    "\n",
    "            # Check how many we got correct\n",
    "            num_correct += (predictions == y).sum()\n",
    "\n",
    "            # Keep track of number of samples\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "    model.train()\n",
    "    return num_correct / num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 96.74\n",
      "Accuracy on test set: 96.56\n"
     ]
    }
   ],
   "source": [
    "# Check accuracy on training & test to see how good our model\n",
    "print(f\"Accuracy on training set: {check_accuracy(train_datloader, model)*100:.2f}\")\n",
    "print(f\"Accuracy on test set: {check_accuracy(test_datloader, model)*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
