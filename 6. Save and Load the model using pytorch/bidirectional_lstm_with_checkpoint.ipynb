{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transformations\n",
    "import torch.onnx as onnx\n",
    "import onnxruntime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Bidirectional Lstm Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BLSTM(nn.Module):\n",
    "    def __init__(self, imp_emb_dim, hidden_units, n_layers, output_classes):\n",
    "        super(BLSTM, self).__init__()\n",
    "\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_units = hidden_units\n",
    "\n",
    "        self.bilstm = nn.LSTM(input_size=imp_emb_dim,\n",
    "                               hidden_size=hidden_units,\n",
    "                               num_layers=n_layers,\n",
    "                               batch_first=True,\n",
    "                               bidirectional=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_units*imp_emb_dim*2, output_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Initialize the hidden state and cell state first for bidrectional lstm\n",
    "        h0 = torch.zeros(self.n_layers*2, x.size(0), self.hidden_units).to(device)\n",
    "        c0 = torch.zeros(self.n_layers*2, x.size(0), self.hidden_units).to(device)\n",
    "        \n",
    "        # Forward Propagation\n",
    "        out, _ = self.bilstm(x, (h0, c0))\n",
    "        out_flatten = torch.flatten(out, 1,-1)\n",
    "        x = self.fc(out_flatten)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "# check the network graph\n",
    "model = BLSTM(28, 5, 10, 10)\n",
    "\n",
    "# create a random variable and pass it to the model to check the network graph\n",
    "device = 'cpu'\n",
    "x = torch.randn(64, 28, 28)\n",
    "h0 = torch.zeros(10*2, x.size(0), 5).to(device)\n",
    "c0 = torch.zeros(10*2, x.size(0), 5).to(device)\n",
    "\n",
    "\n",
    "print(x.shape)\n",
    "print(model(x).shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for network initialisation\n",
    "n_class = 10\n",
    "n_layer = 10\n",
    "hidden_size = 5\n",
    "emb_dim = 28\n",
    "batch_size = 64\n",
    "\n",
    "max_seq_length = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BLSTM(\n",
       "  (bilstm): LSTM(28, 5, num_layers=10, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=280, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model architecture\n",
    "model = BLSTM(emb_dim, hidden_size, n_layer, n_class)\n",
    "# Use the gpu if possible\n",
    "model = model.to(device)\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load('../checkpoint.pth.tar')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note: Be sure to call model.eval() method before inferencing to set the dropout and batch normalization layers to evaluation mode. Failing to do this will yield inconsistent inference results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.2027, -4.8936, -1.1561,  0.0267, -2.2498,  6.2669, -2.4640,  1.7017,\n",
       "          2.8472, -0.4104]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the model with a pseudo input image\n",
    "input_image = torch.zeros((1,28,28)).to(device)\n",
    "model(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aditya\\miniconda3\\envs\\learn_pytorch\\lib\\site-packages\\torch\\onnx\\symbolic_opset9.py:4476: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Export the model using onnx\n",
    "onnx_model = '../model.onnx'\n",
    "onnx.export(model, input_image, onnx_model, verbose= True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and load the data from pytorch sample datasets\n",
    "# https://pytorch.org/vision/0.8/datasets.html\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"../dataset/\", train=True, transform=transformations.ToTensor(), download=True\n",
    ")\n",
    "train_datloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset shape: torch.Size([60000, 28, 28])\n",
      "['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n"
     ]
    }
   ],
   "source": [
    "# train data shape and class labels\n",
    "print(\"train_dataset shape:\", train_dataset.data.shape)\n",
    "print(train_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_dataset shape: torch.Size([10000, 28, 28])\n",
      "['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n"
     ]
    }
   ],
   "source": [
    "test_dataset = datasets.MNIST(\n",
    "    root=\"../dataset/\", train=False, transform=transformations.ToTensor(), download=True\n",
    ")\n",
    "test_datloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(\"test_dataset shape:\", test_dataset.data.shape)\n",
    "print(test_dataset.classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"7 - seven\", Actual: \"7 - seven\"\n"
     ]
    }
   ],
   "source": [
    "session = onnxruntime.InferenceSession(onnx_model, None)\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n",
    "# Load a test datapoint\n",
    "x, y = test_dataset[0]\n",
    "\n",
    "# Get class label list\n",
    "classes = test_dataset.classes\n",
    "\n",
    "# Prediction\n",
    "result = session.run([output_name], {input_name: x.numpy()})\n",
    "predicted, actual = classes[result[0][0].argmax(0)], classes[y]\n",
    "print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
