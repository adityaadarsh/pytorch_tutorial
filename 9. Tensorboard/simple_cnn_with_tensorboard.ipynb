{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Course Reference: https://learn.microsoft.com/en-us/training/modules/intro-machine-learning-pytorch/8-quickstart\n",
    "#### Learning objectives\n",
    "\n",
    "In this module you will:\n",
    "\n",
    "* Learn how create a asimple CNN using pytorch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transformations\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a CNN Network \n",
    "\n",
    "We define our neural network by subclassing nn.Module, and initialize the neural network layers in __init__. Every nn.Module subclass implements the operations on input data in the forward method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import nn module\n",
    "# Init super class\n",
    "# input  -> input channels\n",
    "# design a CONV layer\n",
    "# Check output size at each layer using pseudo forwaard\n",
    "# Add a max pool layer\n",
    "# what is the output of the maxpool?\n",
    "# conv 2\n",
    "# Fc1\n",
    "# Forward pass operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCnn(nn.Module):\n",
    "    def __init__(self, input_channel, output_class):\n",
    "        super(SimpleCnn, self).__init__()\n",
    "\n",
    "        # CNN layers\n",
    "        self.conv_layer_1 = nn.Conv2d(\n",
    "            in_channels=input_channel,\n",
    "            out_channels=8,\n",
    "            kernel_size=(3, 3),\n",
    "            padding=(1, 1),\n",
    "            stride=(1, 1),\n",
    "        )\n",
    "\n",
    "        self.pool_layer = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "        self.conv_layer_2 = nn.Conv2d(\n",
    "            in_channels=8,\n",
    "            out_channels=16,\n",
    "            kernel_size=(3, 3),\n",
    "            padding=(1, 1),\n",
    "            stride=(1, 1),\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=16 * 7 * 7, out_features=output_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv_layer_1(x))\n",
    "        x = self.pool_layer(x)\n",
    "        x = F.relu(self.conv_layer_2(x))\n",
    "        x = self.pool_layer(x)\n",
    "        x = x.flatten(1, -1)\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the network graph\n",
    "model = SimpleCnn(1, 10)\n",
    "\n",
    "# create a random variable and pass it to the model to check the network graph\n",
    "x = torch.randn(60, 1, 28, 28)\n",
    "print(x.shape)\n",
    "print(model(x).shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and load the data from pytorch sample datasets\n",
    "# https://pytorch.org/vision/0.8/datasets.html\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"../dataset/\", train=True, transform=transformations.ToTensor(), download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data shape and class labels\n",
    "print(\"train_dataset shape:\", train_dataset.data.shape)\n",
    "print(train_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = datasets.MNIST(\n",
    "    root=\"../dataset/\", train=False, transform=transformations.ToTensor(), download=True\n",
    ")\n",
    "print(\"test_dataset shape:\", test_dataset.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameter\n",
    "input_channel = 1\n",
    "n_class = 10\n",
    "learning_rates = [0.1]\n",
    "batch_size = [16, 64]\n",
    "num_epochs = 5\n",
    "\n",
    "# Class label\n",
    "classes = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and logging parameters into the tensorboard\n",
    "for batch_size in batch_size:\n",
    "    for learning_rate in learning_rates:\n",
    "        step = 0\n",
    "        # Initialize network\n",
    "        model = SimpleCnn(input_channel=input_channel, output_class=n_class)\n",
    "        model.to(device)\n",
    "        model.train()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        train_loader = DataLoader(\n",
    "            dataset=train_dataset, batch_size=batch_size, shuffle=True\n",
    "        )\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0)\n",
    "        writer = SummaryWriter(\n",
    "            f\"runs/MNIST/MiniBatchSize {batch_size} LR {learning_rate}\"\n",
    "        )\n",
    "\n",
    "        # Visualize model in TensorBoard\n",
    "        images, _ = next(iter(train_loader))\n",
    "        writer.add_graph(model, images.to(device))\n",
    "        writer.close()\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            losses = []\n",
    "            accuracies = []\n",
    "\n",
    "            for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "                # Get data to cuda if possible\n",
    "                data = data.to(device=device)\n",
    "                targets = targets.to(device=device)\n",
    "\n",
    "                # forward\n",
    "                scores = model(data)\n",
    "                loss = criterion(scores, targets)\n",
    "                losses.append(loss.item())\n",
    "\n",
    "                # backward\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Calculate 'running' training accuracy\n",
    "                features = data.reshape(data.shape[0], -1)\n",
    "                img_grid = torchvision.utils.make_grid(data)\n",
    "                _, predictions = scores.max(1)\n",
    "                num_correct = (predictions == targets).sum()\n",
    "                running_train_acc = float(num_correct) / float(data.shape[0])\n",
    "                accuracies.append(running_train_acc)\n",
    "\n",
    "                # Plot things to tensorboard\n",
    "                class_labels = [classes[label] for label in predictions]\n",
    "                writer.add_image(\"mnist_images\", img_grid)\n",
    "                writer.add_histogram(\"fc1\", model.fc1.weight)\n",
    "                writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "                writer.add_scalar(\n",
    "                    \"Training Accuracy\", running_train_acc, global_step=step\n",
    "                )\n",
    "\n",
    "                if batch_idx == 230:\n",
    "                    writer.add_embedding(\n",
    "                        features,\n",
    "                        metadata=class_labels,\n",
    "                        label_img=data,\n",
    "                        global_step=batch_idx,\n",
    "                    )\n",
    "                step += 1\n",
    "\n",
    "            writer.add_hparams(\n",
    "                {\"lr\": learning_rate, \"bsize\": batch_size},\n",
    "                {\n",
    "                    \"accuracy\": sum(accuracies) / len(accuracies),\n",
    "                    \"loss\": sum(losses) / len(losses),\n",
    "                },\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
